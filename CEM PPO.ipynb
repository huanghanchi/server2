{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "import gym\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\t# 各种层类型的实现\n",
    "import torch.nn.functional as F\t# 各中层函数的实现，与层类型对应，如：卷积函数、池化函数、归一化函数等等\n",
    "import torch.optim as optim\t# 实现各种优化算法的包\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import permutation\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_data import GridData\n",
    "\n",
    "from compute_mpe import CircuitMPE\n",
    "import sys\n",
    "sys.path.insert(0,'/root/gurobi903/linux64/lib/python3.6_utf32/gurobipy')\n",
    "import gurobipy\n",
    "cmpe = CircuitMPE('/root/PySDD/notebooks/yahoo.vtree', '/root/PySDD/notebooks/yahoo.sdd')\n",
    "class para:\n",
    "    def __init__(self):\n",
    "        self.batch_size=16\n",
    "        self.wmc=10\n",
    "        self.solDim=24\n",
    "        self.card=20\n",
    "        self.test_batch_size=1000\n",
    "        self.epochs=10\n",
    "        self.lr=0.1\n",
    "        self.momentum=0.5\n",
    "        self.no_cuda='store_true'\n",
    "        self.seed=1\n",
    "        self.log_interval=10\n",
    "        self.hidden_dim=10\n",
    "args=para()\n",
    "#legalList={0: [46], 1: [59], 2: [53, 63, 86], 3: [17, 22, 23, 24, 26, 34, 51, 61, 66, 74, 81, 85, 87, 89, 90, 96], 4: [24, 26, 37, 71, 83, 87, 94, 99], 5: [96], 6: [38], 7: [85], 8: [19, 64], 9: [], 10: [], 11: [], 12: [17, 79, 81], 13: [17, 23, 24, 25, 26, 30, 36, 42, 54, 56, 61, 66, 68, 72, 77, 81, 84, 89, 92, 95], 14: [], 15: [], 16: [17, 24, 25, 27, 35, 39, 42, 46, 48, 56, 61, 66, 72, 76, 81, 84, 89], 17: [3, 12, 13, 16, 24, 25, 27, 29, 35, 39, 42, 46, 51, 52, 54, 56, 61, 66, 72, 76, 77, 79, 81, 85, 89, 92, 96], 18: [], 19: [8, 37, 64, 70, 91], 20: [], 21: [], 22: [3, 30, 61, 66, 78, 81, 85, 90, 96], 23: [3, 13, 61, 66, 89], 24: [3, 4, 13, 16, 17, 25, 26, 27, 31, 34, 38, 42, 51, 54, 56, 61, 66, 68, 72, 74, 76, 77, 81, 84, 87, 89, 99], 25: [13, 16, 17, 24, 27, 35, 36, 39, 40, 42, 48, 51, 52, 54, 56, 61, 66, 68, 72, 76, 77, 81, 84, 89, 92], 26: [3, 4, 13, 24, 34, 42, 54, 66, 74, 77, 81, 83, 92, 97], 27: [16, 17, 24, 25, 35, 39, 46, 51, 52, 61, 68, 76, 87, 99], 28: [], 29: [17, 35, 56, 66, 72, 79, 81, 89], 30: [13, 22, 54, 61, 66, 73, 75, 78, 81, 95], 31: [24, 46, 51, 52, 61, 76, 79], 32: [], 33: [], 34: [3, 24, 26, 54, 66, 71, 74, 77, 81, 84, 94], 35: [16, 17, 25, 27, 29, 36, 39, 40, 46, 48, 52, 56, 61, 66, 72, 76, 77, 81, 89], 36: [13, 25, 35, 42, 56, 57, 66, 77, 81, 84, 89, 92], 37: [4, 19, 51, 64, 87, 99], 38: [6, 24, 51, 63, 67, 99], 39: [16, 17, 25, 27, 35, 48, 56, 61, 76, 77, 81, 85, 89], 40: [25, 35], 41: [], 42: [13, 16, 17, 24, 25, 26, 36, 54, 56, 61, 66, 68, 72, 76, 77, 81, 84, 89, 92], 43: [], 44: [51, 74], 45: [], 46: [0, 16, 17, 27, 31, 35, 51, 52, 61, 76, 96], 47: [], 48: [16, 25, 35, 39, 56, 61, 66, 77, 89], 49: [], 50: [], 51: [3, 17, 24, 25, 27, 31, 37, 38, 44, 46, 61, 68, 76, 87, 94, 99], 52: [17, 25, 27, 31, 35, 46, 61, 72, 76, 79, 81, 89], 53: [2, 70, 86, 93], 54: [13, 17, 24, 25, 26, 30, 34, 42, 56, 61, 66, 68, 72, 77, 81, 84, 89, 92, 95], 55: [], 56: [13, 16, 17, 24, 25, 29, 35, 36, 39, 42, 48, 54, 61, 66, 77, 81, 84, 89, 92], 57: [36], 58: [], 59: [1], 60: [], 61: [3, 13, 16, 17, 22, 23, 24, 25, 27, 30, 31, 35, 39, 42, 46, 48, 51, 52, 54, 56, 66, 72, 76, 77, 79, 81, 84, 85, 87, 89, 90, 96], 62: [], 63: [2, 38], 64: [8, 19, 37, 74, 87, 91], 65: [], 66: [3, 13, 16, 17, 22, 23, 24, 25, 26, 29, 30, 34, 35, 36, 42, 48, 54, 56, 61, 72, 73, 74, 76, 77, 81, 84, 85, 89, 92], 67: [38], 68: [13, 24, 25, 27, 42, 51, 54, 87, 99], 69: [], 70: [19, 53], 71: [4, 34, 74], 72: [13, 16, 17, 24, 25, 29, 35, 42, 52, 54, 61, 66, 76, 79, 81, 89], 73: [30, 66, 78, 84], 74: [3, 24, 26, 34, 44, 64, 66, 71, 77, 83], 75: [30], 76: [16, 17, 24, 25, 27, 31, 35, 39, 42, 46, 51, 52, 61, 66, 72, 79, 81, 89, 96], 77: [13, 17, 24, 25, 26, 34, 35, 36, 39, 42, 48, 54, 56, 61, 66, 74, 81, 84, 89, 92], 78: [22, 30, 73, 85, 90], 79: [12, 17, 29, 31, 52, 61, 72, 76, 81, 89], 80: [], 81: [3, 12, 13, 16, 17, 22, 24, 25, 26, 29, 30, 34, 35, 36, 39, 42, 52, 54, 56, 61, 66, 72, 76, 77, 79, 84, 85, 89, 92, 95], 82: [], 83: [4, 26, 74], 84: [13, 16, 24, 25, 34, 36, 42, 54, 56, 61, 66, 73, 77, 81, 89], 85: [3, 7, 17, 22, 39, 61, 66, 78, 81, 89, 90], 86: [2, 53, 88, 91], 87: [3, 4, 24, 27, 37, 51, 61, 64, 68, 91, 94, 99], 88: [86], 89: [3, 13, 16, 17, 23, 24, 25, 29, 35, 36, 39, 42, 48, 52, 54, 56, 61, 66, 72, 76, 77, 79, 81, 84, 85, 92], 90: [3, 22, 61, 78, 85], 91: [19, 64, 86, 87, 94], 92: [13, 17, 25, 26, 36, 42, 54, 56, 66, 77, 81, 89, 95], 93: [53], 94: [4, 34, 51, 87, 91, 99], 95: [13, 30, 54, 81, 92], 96: [3, 5, 17, 22, 46, 61, 76], 97: [26], 98: [], 99: [4, 24, 27, 37, 38, 51, 68, 87, 94]}\n",
    "legalList={0: [13, 18],\n",
    " 1: [17, 20, 22],\n",
    " 2: [4, 5, 10, 13, 14, 16, 17, 18, 20, 22],\n",
    " 3: [5, 9, 11, 12, 15],\n",
    " 4: [2, 10, 13, 14, 16, 17, 18, 20, 22],\n",
    " 5: [2, 3, 6, 9, 10, 11, 12, 14, 16],\n",
    " 6: [5, 15],\n",
    " 7: [],\n",
    " 8: [],\n",
    " 9: [3, 5, 11, 12, 15],\n",
    " 10: [2, 4, 5, 14, 16, 22],\n",
    " 11: [3, 5, 9, 12, 15],\n",
    " 12: [3, 5, 9, 11, 15],\n",
    " 13: [0, 2, 4, 14, 18, 22],\n",
    " 14: [2, 4, 5, 10, 13, 16, 17, 18, 20, 22],\n",
    " 15: [3, 6, 9, 11, 12, 17, 19, 20],\n",
    " 16: [2, 4, 5, 10, 14, 22],\n",
    " 17: [1, 2, 4, 14, 15, 19, 20, 22],\n",
    " 18: [0, 2, 4, 13, 14, 22],\n",
    " 19: [15, 17, 20],\n",
    " 20: [1, 2, 4, 14, 15, 17, 19, 22],\n",
    " 21: [],\n",
    " 22: [1, 2, 4, 10, 13, 14, 16, 17, 18, 20],\n",
    " 23: []}\n",
    "def checkFea(x):\n",
    "    cnt=0\n",
    "    cntT=0\n",
    "    for i in range(len(legalList.keys())):\n",
    "        for j in legalList[i]:\n",
    "            cntT+=1\n",
    "            if x[j]+x[i]>1:\n",
    "                cnt+=1\n",
    "    return cnt/cntT#/2+abs(x.sum()-args.card)/args.card/2\n",
    "def CB(alpha,x,M):\n",
    "    return alpha*np.sqrt(np.dot(np.dot(x.T,np.linalg.inv(M)),x))\n",
    "def solver(theta,MODEL):\n",
    "\n",
    "    import gurobipy\n",
    "    import time\n",
    "    s=time.time()\n",
    "    # 创建模型\n",
    "    variables=[]\n",
    "    for i in range(args.solDim):\n",
    "        variables.append(MODEL.addVar(vtype=gurobipy.GRB.BINARY, name='x'+'i'))\n",
    "    # 更新变量环境\n",
    "    MODEL.update()\n",
    "\n",
    "    # 创建目标函数\n",
    "    MODEL.setObjective(np.array(variables).dot(theta), sense=gurobipy.GRB.MAXIMIZE)\n",
    "\n",
    "    # 创建约束条件\n",
    "    cnt=0\n",
    "    for i in range(args.solDim):\n",
    "        if len(legalList)>0:\n",
    "            for j in legalList[i]:\n",
    "                MODEL.addConstr(-variables[i]-variables[j] >= -1, name=str(cnt))\n",
    "                cnt+=1\n",
    "    MODEL.addConstr(sum(variables) == args.card, name=str(cnt))\n",
    "    f=time.time()\n",
    "    # 执行最优化\n",
    "    MODEL.optimize()\n",
    "    return np.array(MODEL.x)\n",
    "def solver_quad(Q,MODEL):\n",
    "\n",
    "    import gurobipy\n",
    "    import time\n",
    "    s=time.time()\n",
    "    # 创建模型\n",
    "    variables=[]\n",
    "    for i in range(args.solDim):\n",
    "        variables.append(MODEL.addVar(vtype=gurobipy.GRB.BINARY, name='x'+'i'))\n",
    "    # 更新变量环境\n",
    "    MODEL.update()\n",
    "\n",
    "    # 创建目标函数\n",
    "    MODEL.setObjective(np.array(variables).dot(Q).dot(np.array(variables)), sense=gurobipy.GRB.MAXIMIZE)\n",
    "\n",
    "    # 创建约束条件\n",
    "    cnt=0\n",
    "    for i in range(args.solDim):\n",
    "        if len(legalList)>0:\n",
    "            for j in legalList[i]:\n",
    "                MODEL.addConstr(-variables[i]-variables[j] >= -1, name=str(cnt))\n",
    "                cnt+=1\n",
    "    MODEL.addConstr(sum(variables) == args.card, name=str(cnt))\n",
    "    f=time.time()\n",
    "    # 执行最优化\n",
    "    \n",
    "    print('??')\n",
    "    MODEL.optimize()\n",
    "    print('??')\n",
    "    return np.array(MODEL.x)\n",
    "a=10*(np.load('rateListUsersYahoo.npy')[0]-np.load('rateListUsersYahoo.npy')[0].min())#np.random.random(24) #  np.load('rateListUsersYahoo.npy')[0]\n",
    "#10*(np.load('rateListml100.npy')-np.load('rateListml100.npy').min())\n",
    "a /= np.linalg.norm(a, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 4.428571428571429 0.42857142857142855\n",
      "2 5.8730158730158735 0.20634920634920634\n",
      "3 8.603174603174605 0.2698412698412698\n",
      "4 6.142857142857143 0.14285714285714285\n",
      "5 6.238095238095238 0.23809523809523808\n",
      "6 7.142857142857143 0.14285714285714285\n",
      "7 7.682539682539683 0.015873015873015872\n",
      "8 6.825396825396826 0.15873015873015872\n",
      "9 5.380952380952381 0.38095238095238093\n",
      "10 7.73015873015873 0.06349206349206349\n",
      "11 6.968253968253968 0.30158730158730157\n",
      "12 6.8730158730158735 0.20634920634920634\n",
      "13 5.777777777777778 0.1111111111111111\n",
      "14 6.238095238095238 0.23809523809523808\n",
      "15 6.507936507936508 0.1746031746031746\n",
      "16 8.650793650793652 0.31746031746031744\n",
      "17 4.793650793650794 0.4603174603174603\n",
      "18 4.333333333333334 0.3333333333333333\n",
      "19 7.015873015873016 0.3492063492063492\n",
      "20 7.142857142857143 0.14285714285714285\n",
      "0 tensor(-1.3145e-12, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-16.1196, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-32.1870, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-48.1990, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-64.1517, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "21 6.190476190476191 0.19047619047619047\n",
      "22 8.603174603174605 0.2698412698412698\n",
      "23 6.777777777777778 0.1111111111111111\n",
      "24 5.777777777777778 0.1111111111111111\n",
      "25 8.555555555555555 0.2222222222222222\n",
      "26 7.603174603174604 0.2698412698412698\n",
      "27 3.571428571428573 0.5714285714285714\n",
      "28 7.095238095238095 0.09523809523809523\n",
      "29 7.238095238095238 0.23809523809523808\n",
      "30 5.8730158730158735 0.20634920634920634\n",
      "31 5.793650793650794 0.4603174603174603\n",
      "32 8.19047619047619 0.19047619047619047\n",
      "33 7.015873015873016 0.3492063492063492\n",
      "34 6.920634920634921 0.25396825396825395\n",
      "35 6.238095238095238 0.23809523809523808\n",
      "36 7.603174603174604 0.2698412698412698\n",
      "37 5.507936507936508 0.1746031746031746\n",
      "38 5.603174603174604 0.2698412698412698\n",
      "39 6.8730158730158735 0.20634920634920634\n",
      "40 5.777777777777778 0.1111111111111111\n",
      "0 tensor(-1.0552e-12, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-12.1197, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-24.1784, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-36.1695, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-48.0843, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "41 6.603174603174604 0.2698412698412698\n",
      "42 4.920634920634921 0.25396825396825395\n",
      "43 7.412698412698413 0.07936507936507936\n",
      "44 7.825396825396826 0.15873015873015872\n",
      "45 7.507936507936508 0.1746031746031746\n",
      "46 6.095238095238095 0.09523809523809523\n",
      "47 8.507936507936508 0.1746031746031746\n",
      "48 7.4603174603174605 0.12698412698412698\n",
      "49 8.555555555555555 0.2222222222222222\n",
      "50 6.142857142857143 0.14285714285714285\n",
      "51 6.507936507936508 0.1746031746031746\n",
      "52 7.4603174603174605 0.12698412698412698\n",
      "53 5.4603174603174605 0.12698412698412698\n",
      "54 7.555555555555555 0.2222222222222222\n",
      "55 7.507936507936508 0.1746031746031746\n",
      "56 9.238095238095237 0.23809523809523808\n",
      "57 8.19047619047619 0.19047619047619047\n",
      "58 7.920634920634921 0.25396825396825395\n",
      "59 7.412698412698413 0.07936507936507936\n",
      "60 6.507936507936508 0.1746031746031746\n",
      "0 tensor(1.5312e-12, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-10.8175, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-21.5498, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-32.1692, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-42.5990, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "61 4.777777777777778 0.1111111111111111\n",
      "62 7.190476190476191 0.19047619047619047\n",
      "63 6.4603174603174605 0.12698412698412698\n",
      "64 6.825396825396826 0.15873015873015872\n",
      "65 6.0476190476190474 0.047619047619047616\n",
      "66 7.4603174603174605 0.12698412698412698\n",
      "67 6.8730158730158735 0.20634920634920634\n",
      "68 5.555555555555555 0.2222222222222222\n",
      "69 6.2857142857142865 0.2857142857142857\n",
      "70 9.46031746031746 0.12698412698412698\n",
      "71 3.238095238095238 0.23809523809523808\n",
      "72 5.8730158730158735 0.20634920634920634\n",
      "73 6.412698412698413 0.07936507936507936\n",
      "74 7.777777777777778 0.1111111111111111\n",
      "75 6.777777777777778 0.1111111111111111\n",
      "76 6.73015873015873 0.06349206349206349\n",
      "77 5.4603174603174605 0.12698412698412698\n",
      "78 4.0 0.0\n",
      "79 4.238095238095238 0.23809523809523808\n",
      "80 6.8730158730158735 0.20634920634920634\n",
      "0 tensor(-6.6347e-13, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-8.0363, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-15.9688, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-23.7550, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-31.2944, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "81 7.0476190476190474 0.047619047619047616\n",
      "82 5.920634920634921 0.25396825396825395\n",
      "83 6.603174603174604 0.2698412698412698\n",
      "84 6.238095238095238 0.23809523809523808\n",
      "85 9.19047619047619 0.19047619047619047\n",
      "86 4.4603174603174605 0.12698412698412698\n",
      "87 6.682539682539683 0.015873015873015872\n",
      "88 4.8730158730158735 0.20634920634920634\n",
      "89 8.142857142857142 0.14285714285714285\n",
      "90 4.2857142857142865 0.2857142857142857\n",
      "91 5.238095238095238 0.23809523809523808\n",
      "92 5.650793650793651 0.31746031746031744\n",
      "93 7.142857142857143 0.14285714285714285\n",
      "94 8.777777777777779 0.1111111111111111\n",
      "95 4.428571428571429 0.42857142857142855\n",
      "96 7.142857142857143 0.14285714285714285\n",
      "97 6.777777777777778 0.1111111111111111\n",
      "98 6.8730158730158735 0.20634920634920634\n",
      "99 8.777777777777779 0.1111111111111111\n",
      "100 5.190476190476191 0.19047619047619047\n",
      "101 6.507936507936508 0.1746031746031746\n",
      "102 6.0476190476190474 0.047619047619047616\n",
      "103 6.698412698412699 0.36507936507936506\n",
      "104 6.238095238095238 0.23809523809523808\n",
      "105 6.825396825396826 0.15873015873015872\n",
      "106 6.412698412698413 0.07936507936507936\n",
      "107 5.190476190476191 0.19047619047619047\n",
      "108 8.238095238095237 0.23809523809523808\n",
      "109 6.777777777777778 0.1111111111111111\n",
      "110 3.8730158730158735 0.20634920634920634\n",
      "111 8.095238095238095 0.09523809523809523\n",
      "112 5.777777777777778 0.1111111111111111\n",
      "113 7.142857142857143 0.14285714285714285\n",
      "114 8.285714285714286 0.2857142857142857\n",
      "115 5.920634920634921 0.25396825396825395\n",
      "116 6.190476190476191 0.19047619047619047\n",
      "117 5.968253968253968 0.30158730158730157\n",
      "118 6.73015873015873 0.06349206349206349\n",
      "119 5.190476190476191 0.19047619047619047\n",
      "120 8.285714285714286 0.2857142857142857\n",
      "0 tensor(-9.5657e-13, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-10.3462, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-20.5863, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-30.6738, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-40.4685, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "121 6.825396825396826 0.15873015873015872\n",
      "122 4.825396825396826 0.15873015873015872\n",
      "123 6.777777777777778 0.1111111111111111\n",
      "124 5.4603174603174605 0.12698412698412698\n",
      "125 6.142857142857143 0.14285714285714285\n",
      "126 7.603174603174604 0.2698412698412698\n",
      "127 6.238095238095238 0.23809523809523808\n",
      "128 7.015873015873016 0.3492063492063492\n",
      "129 7.412698412698413 0.07936507936507936\n",
      "130 6.73015873015873 0.06349206349206349\n",
      "131 7.095238095238095 0.09523809523809523\n",
      "132 6.4603174603174605 0.12698412698412698\n",
      "133 7.142857142857143 0.14285714285714285\n",
      "134 5.015873015873016 0.3492063492063492\n",
      "135 9.142857142857142 0.14285714285714285\n",
      "136 6.095238095238095 0.09523809523809523\n",
      "137 5.777777777777778 0.1111111111111111\n",
      "138 6.8730158730158735 0.20634920634920634\n",
      "139 5.603174603174604 0.2698412698412698\n",
      "140 6.0476190476190474 0.047619047619047616\n",
      "0 tensor(5.2579e-13, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-9.0437, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-18.0078, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-26.8981, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-35.7183, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "141 5.8730158730158735 0.20634920634920634\n",
      "142 8.730158730158731 0.06349206349206349\n",
      "143 4.825396825396826 0.15873015873015872\n",
      "144 6.4603174603174605 0.12698412698412698\n",
      "145 7.190476190476191 0.19047619047619047\n",
      "146 6.095238095238095 0.09523809523809523\n",
      "147 7.095238095238095 0.09523809523809523\n",
      "148 6.8730158730158735 0.20634920634920634\n",
      "149 7.238095238095238 0.23809523809523808\n",
      "150 8.047619047619047 0.047619047619047616\n",
      "151 5.73015873015873 0.06349206349206349\n",
      "152 4.920634920634921 0.25396825396825395\n",
      "153 6.142857142857143 0.14285714285714285\n",
      "154 7.777777777777778 0.1111111111111111\n",
      "155 7.365079365079366 0.031746031746031744\n",
      "156 7.142857142857143 0.14285714285714285\n",
      "157 7.190476190476191 0.19047619047619047\n",
      "158 7.825396825396826 0.15873015873015872\n",
      "159 5.238095238095238 0.23809523809523808\n",
      "160 7.825396825396826 0.15873015873015872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(-5.0804e-13, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-5.2248, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-10.3775, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-15.4556, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-20.4546, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "161 4.555555555555555 0.2222222222222222\n",
      "162 6.412698412698413 0.07936507936507936\n",
      "163 6.555555555555555 0.2222222222222222\n",
      "164 6.095238095238095 0.09523809523809523\n",
      "165 7.4603174603174605 0.12698412698412698\n",
      "166 6.015873015873016 0.3492063492063492\n",
      "167 5.095238095238095 0.09523809523809523\n",
      "168 7.142857142857143 0.14285714285714285\n",
      "169 7.412698412698413 0.07936507936507936\n",
      "170 8.142857142857142 0.14285714285714285\n",
      "171 5.333333333333334 0.3333333333333333\n",
      "172 5.777777777777778 0.1111111111111111\n",
      "173 5.920634920634921 0.25396825396825395\n",
      "174 7.825396825396826 0.15873015873015872\n",
      "175 6.555555555555555 0.2222222222222222\n",
      "176 7.682539682539683 0.015873015873015872\n",
      "177 4.412698412698413 0.07936507936507936\n",
      "178 4.73015873015873 0.06349206349206349\n",
      "179 7.111111111111111 0.4444444444444444\n",
      "180 4.190476190476191 0.19047619047619047\n",
      "0 tensor(-2.9559e-12, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-18.6791, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-37.2836, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-55.8120, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "4 tensor(-74.2609, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "181 6.142857142857143 0.14285714285714285\n",
      "182 6.0476190476190474 0.047619047619047616\n",
      "183 5.4603174603174605 0.12698412698412698\n",
      "184 3.5555555555555554 0.2222222222222222\n",
      "185 5.920634920634921 0.25396825396825395\n",
      "186 6.777777777777778 0.1111111111111111\n",
      "187 7.0476190476190474 0.047619047619047616\n",
      "188 3.412698412698413 0.07936507936507936\n",
      "189 3.0 0.0\n",
      "190 5.238095238095238 0.23809523809523808\n",
      "191 5.73015873015873 0.06349206349206349\n",
      "192 6.412698412698413 0.07936507936507936\n",
      "193 5.4603174603174605 0.12698412698412698\n",
      "194 6.4603174603174605 0.12698412698412698\n",
      "195 6.4603174603174605 0.12698412698412698\n",
      "196 6.365079365079366 0.031746031746031744\n",
      "197 7.777777777777778 0.1111111111111111\n",
      "198 4.507936507936508 0.1746031746031746\n",
      "199 7.095238095238095 0.09523809523809523\n",
      "200 4.095238095238095 0.09523809523809523\n",
      "201 6.73015873015873 0.06349206349206349\n",
      "202 7.142857142857143 0.14285714285714285\n",
      "203 5.777777777777778 0.1111111111111111\n",
      "204 4.73015873015873 0.06349206349206349\n",
      "205 6.4603174603174605 0.12698412698412698\n",
      "206 6.777777777777778 0.1111111111111111\n",
      "207 5.507936507936508 0.1746031746031746\n",
      "208 5.777777777777778 0.1111111111111111\n",
      "209 5.73015873015873 0.06349206349206349\n",
      "210 4.968253968253968 0.30158730158730157\n",
      "211 6.190476190476191 0.19047619047619047\n",
      "212 5.73015873015873 0.06349206349206349\n",
      "213 5.825396825396826 0.15873015873015872\n",
      "214 3.9682539682539684 0.30158730158730157\n",
      "215 6.095238095238095 0.09523809523809523\n",
      "216 7.507936507936508 0.1746031746031746\n",
      "217 6.412698412698413 0.07936507936507936\n",
      "218 5.73015873015873 0.06349206349206349\n",
      "219 6.507936507936508 0.1746031746031746\n",
      "220 7.0476190476190474 0.047619047619047616\n",
      "0 tensor(1.6964e-13, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "1 tensor(-3.0519, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "2 tensor(-6.0275, dtype=torch.float64, grad_fn=<NegBackward>)\n",
      "3 tensor(-8.9348, dtype=torch.float64, grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-075e6f07690e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0muNext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0mpre\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mPPOobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muNext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;31m#pre.requires_grad=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "eps=0.03\n",
    "jitter=0.05\n",
    "beta=0.2\n",
    "rho=0.1\n",
    "b=200\n",
    "N=100\n",
    "K=20\n",
    "L=100000\n",
    "constraintMean=0.2\n",
    "def PPOobj(uNext,u):\n",
    "    obj=0.\n",
    "    for i in range(K):\n",
    "        for j in range(args.solDim):\n",
    "            if actions[i][j]==1:\n",
    "                obj+=(uNext[j]/u[j])*(b-rewards[i])\n",
    "            else:\n",
    "                obj+=((1-uNext[j])/(1-u[j]))*(b-rewards[i])\n",
    "            obj-=(beta*(u[j]*torch.log(u[j]/uNext[j])))\n",
    "            obj-=(beta*(u[j]*torch.log(u[j]/uNext[j])))\n",
    "    return obj\n",
    "def feedback(x):\n",
    "    return (a.dot(x))**3-10*constraintMean*checkFea(x)\n",
    "actions=np.zeros([K,args.solDim])\n",
    "rewards=np.zeros(K)\n",
    "actionsN=np.zeros([N,args.solDim])\n",
    "rewardsN=np.zeros(N)\n",
    "constraintN=np.zeros(N)\n",
    "actionhistoryBest=np.zeros([20,args.solDim])\n",
    "actionhistoryWorst=np.zeros([20,args.solDim])\n",
    "rewardhistoryBest=np.zeros(20)\n",
    "rewardhistoryWorst=np.zeros(20)\n",
    "u=np.random.random([args.solDim])\n",
    "uNext=u.copy()\n",
    "action=[np.random.choice([0,1],size=1,p=[1-u[i],u[i]])[0] for i in range(args.solDim)]\n",
    "reward=sum(action)-20*checkFea(action)\n",
    "actions[0]=action\n",
    "rewards[0]=feedback(action)\n",
    "actionsN[0]=action\n",
    "rewardsN[0]=feedback(action)\n",
    "actionhistoryBest[0]=action\n",
    "actionhistoryWorst[0]=action\n",
    "rewardhistoryBest[0]=feedback(action)\n",
    "rewardhistoryWorst[0]=feedback(action)\n",
    "\n",
    "for t in range(1,L):\n",
    "    u=uNext.copy()\n",
    "    action=[np.random.choice([0,1],size=1,p=[1-u[i],u[i]])[0] for i in range(args.solDim)]\n",
    "    reward=sum(action)-20*checkFea(action)\n",
    "    actions[(t%K)]=action\n",
    "    rewards[(t%K)]=feedback(action)\n",
    "    actionsN[(t%N)]=action\n",
    "    rewardsN[(t%N)]=feedback(action)\n",
    "    constraintN[(t%N)]=checkFea(action)\n",
    "    if t<20:\n",
    "        actionhistoryBest[t]=action\n",
    "        actionhistoryWorst[t]=action\n",
    "        rewardhistoryBest[t]=feedback(action)\n",
    "        rewardhistoryWorst[t]=feedback(action)\n",
    "    else:\n",
    "        if reward>min(rewardhistoryBest) and checkFea(action)<0.15:\n",
    "            actionhistoryBest[np.argwhere(rewardhistoryBest==min(rewardhistoryBest))]=action\n",
    "            rewardhistoryBest[np.argwhere(rewardhistoryBest==min(rewardhistoryBest))]=feedback(action)\n",
    "     #   if reward<max(rewardhistoryWorst) and feedback(action)<0.15:\n",
    "      #      actionhistoryWorst[np.argwhere(rewardhistoryWorst==min(rewardhistoryWorst))]=action\n",
    "       #     rewardhistoryWorst[np.argwhere(rewardhistoryWorst==min(rewardhistoryWorst))]=feedback(action)\n",
    "    print(t,reward,checkFea(action))\n",
    "    if t%K==0 and t%N!=0:\n",
    "        b=rewards.mean()\n",
    "        uNext=torch.tensor(uNext,requires_grad=True)\n",
    "        optimizer=torch.optim.Adam([uNext],lr=1e-2)\n",
    "        for step in range(5):\n",
    "            pre=-PPOobj(uNext,u)\n",
    "            print(step,pre)\n",
    "            #pre.requires_grad=True\n",
    "            optimizer.zero_grad()\n",
    "            pre.backward()\n",
    "            optimizer.step()\n",
    "           # if step % 2000==0:\n",
    "            #    print(step,uNext.tolist(),pre)      \n",
    "        uNext=uNext.detach().numpy()\n",
    "        uNext=np.clip(uNext,jitter,1-jitter)\n",
    "    if t%N==0:\n",
    "        cnt=0\n",
    "        pointer=0\n",
    "        elite=[]\n",
    "        while cnt<int(N*rho) and pointer<N:\n",
    "            if constraintN[np.argsort(rewardsN)[pointer]]<0.15:\n",
    "                elite.append(np.argsort(rewardsN)[pointer])              \n",
    "                cnt+=1\n",
    "            pointer+=1\n",
    "        if cnt<int(N*rho):\n",
    "            while cnt<int(N*rho) and pointer<N:\n",
    "                if np.argsort(rewardsN)[pointer] not in elite:\n",
    "                    elite.append(np.argsort(rewardsN)[pointer])\n",
    "                pointer+=1\n",
    "        tmp=actionsN[elite].reshape([len(elite),args.solDim]).T\n",
    "        for i in range(args.solDim):\n",
    "            uNext[i]=max(min(np.exp(-t/L)*uNext[i] +(1-np.exp(-t/L))*np.sum(tmp[i])/len(elite),1-jitter),jitter)\n",
    "    #    tmphistoryBest=actionhistoryBest.T\n",
    "     #   for i in range(args.solDim):\n",
    "      #      uNext[i]=max(min(uNext[i]/2+np.sum(tmphistoryBest[i])/len(elite)/2,1-jitter),jitter)\n",
    "        constraintMean=constraintN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "全局最佳、sliding window、actionhistoryWorst（吸取教训"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedback(x):\n",
    "    return (a.dot(x))**3-10*constraintMean*checkFea(x)\n",
    "action=[np.random.choice([0,1],size=1,p=[1-u[i],u[i]])[0] for i in range(args.solDim)]\n",
    "reward=sum(action)-20*checkFea(action)\n",
    "actions[0]=action\n",
    "rewards[0]=feedback(action)\n",
    "actionsN[0]=action\n",
    "rewardsN[0]=feedback(action)\n",
    "actionhistoryBest[0]=action\n",
    "rewardhistoryBest[0]=feedback(action)\n",
    "\n",
    "for t in range(1,L):\n",
    "    u=uNext.copy()\n",
    "    action=[np.random.choice([0,1],size=1,p=[1-u[i],u[i]])[0] for i in range(args.solDim)]\n",
    "    reward=sum(action)-20*checkFea(action)\n",
    "    actions[(t%K)]=action\n",
    "    rewards[(t%K)]=feedback(action)\n",
    "    actionsN[(t%N)]=action\n",
    "    rewardsN[(t%N)]=feedback(action)\n",
    "    constraintN[(t%N)]=checkFea(action)\n",
    "    if t<20:\n",
    "        actionhistoryBest[t]=action\n",
    "        rewardhistoryBest[t]=feedback(action)\n",
    "    else:\n",
    "        if reward>min(rewardhistoryBest) and checkFea(action)<0.15:\n",
    "            actionhistoryBest[np.argwhere(rewardhistoryBest==min(rewardhistoryBest))]=action\n",
    "            rewardhistoryBest[np.argwhere(rewardhistoryBest==min(rewardhistoryBest))]=feedback(action)\n",
    "    print(t,reward,checkFea(action))\n",
    "    if t%K==0 and t%N!=0:\n",
    "        b=rewards.mean()\n",
    "        uNext=torch.tensor(uNext,requires_grad=True)\n",
    "        optimizer=torch.optim.Adam([uNext],lr=1e-2)\n",
    "        for step in range(5):\n",
    "            pre=-PPOobj(uNext,u)\n",
    "            print(step,pre)\n",
    "            #pre.requires_grad=True\n",
    "            optimizer.zero_grad()\n",
    "            pre.backward()\n",
    "            optimizer.step()\n",
    "           # if step % 2000==0:\n",
    "            #    print(step,uNext.tolist(),pre)      \n",
    "        uNext=uNext.detach().numpy()\n",
    "        uNext=np.clip(uNext,jitter,1-jitter)\n",
    "    if t%N==0:\n",
    "        cnt=0\n",
    "        pointer=0\n",
    "        elite=[]\n",
    "        while cnt<int(N*rho) and pointer<N:\n",
    "            if constraintN[np.argsort(rewardsN)[pointer]]<0.15:\n",
    "                elite.append(np.argsort(rewardsN)[pointer])              \n",
    "                cnt+=1\n",
    "            pointer+=1\n",
    "        if cnt<int(N*rho):\n",
    "            while cnt<int(N*rho) and pointer<N:\n",
    "                if np.argsort(rewardsN)[pointer] not in elite:\n",
    "                    elite.append(np.argsort(rewardsN)[pointer])\n",
    "                pointer+=1\n",
    "        tmp=actionsN[elite].reshape([len(elite),args.solDim]).T\n",
    "        for i in range(args.solDim):\n",
    "            uNext[i]=max(min(np.exp(-t/L)*uNext[i] +(1-np.exp(-t/L))*np.sum(tmp[i])/len(elite),1-jitter),jitter)\n",
    "        constraintMean=constraintN.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
